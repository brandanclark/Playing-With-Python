#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Sep 21 21:30:38 2022
Practicing Sentiment Analysis using Pandas
From: https://towardsdatascience.com/a-beginners-guide-to-sentiment-analysis-in-python-95e354ea84f6
@author: brandanclark
"""

#import pandas
import pandas as pd

#read Reviews file from Kaggle
df = pd.read_csv('/Users/brandanclark/Desktop/Git/MyFolder/Reviews.csv')
df.head()

#imports, inclduding Plotly
import matplotlib.pyplot as plt
import seaborn as sns
color = sns.color_palette()
%matplotlib inline
import plotly.offline as py
py.init_notebook_mode(connected=True)
import plotly.graph_objs as go
import plotly.tools as tls
import plotly.express as px

#add plotly offline to allow for plot() functionality
from plotly.offline import plot


#create plot looking at Product Scores
fig = px.histogram(df, x="Score")
fig.update_traces(marker_color="turquoise",marker_line_color='rgb(8,48,107)', marker_line_width=1.5)
fig.update_layout(title_text='Product Score')
plot(fig)

#plot suggests that most customer rating data is positive, which should align with sentiment analysis

#classify reviews as positive or negative
#reviews with score > 3 = positive
#score < 3 = negative
#remove score = 3, neutral
df = df[df['Score']!= 3]
df['sentiment'] = df['Score'].apply(lambda rating : +1 if rating > 3 else -1)
df.head()

#code to look at distribution of reviews with sentiment across the dataset
df['sentimentt'] = df['sentiment'].replace({-1 : 'negative'})
df['sentimentt'] = df['sentimentt'].replace({1 : 'positive'})
fig = px.histogram(df, x="sentimentt")
fig.update_traces(marker_color="indianred",marker_line_color='rgb(8,48,107)',
                  marker_line_width=1.5)
fig.update_layout(title_text='Product Sentiment')
fig.show()
plot(fig)

#create and build the sentiment analysis model
#reviews will be the input, model will predict if a review is positive or negative

#import numpy
import numpy as np

#inital data cleaning, removing punctuation
def remove_punctuation(text):
    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", '"'))
    return final

df['Text'] = df['Text'].apply(remove_punctuation)
df = df.dropna(subset=['Summary'])
df['Summary'] = df['Summary'].apply(remove_punctuation)

#create new split dataframe with only summary and sentiment columns
#Q: what is defined as summary data?
dfNew = df[['Summary', 'sentiment']]
dfNew.head()

#split new dataframe into train and test data, 80% train 20% test
index = df.index
df['random_number'] = np.random.randn(len(index))

train = df[df['random_number'] <= 0.8]
test = df[df['random_number'] > 0.8]

#use count vectorizer from Scikit-learn library to create bag of words
#must transform text into bag of words model since logistic regression algorithm cannot understand text
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(token_pattern=r'\b\w+\b')

train_matrix = vectorizer.fit_transform(train['Summary'])
test_matrix = vectorizer.transform(test['Summary'])

#import logistic regression package from sklearn
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(max_iter=10000)

#split target and independent variables
X_train = train_matrix
X_test = test_matrix
y_train = train['sentiment']
y_test = test['sentiment']

#fit model to data
lr.fit(x_train,y_train)

#make predictions using lr
predictions = lr.predict(X_test)

#final step, testing the accuracy of the model, finding accuracy, precision and recall
from sklearn.metrics import confusion_matrix,classification_report
new = np.asarray(y_test)
confusion_matrix(predictions,y_test)

print(classification_report(predictions,y_test))